---
title: "Tarea 4. Estimación por el Método de Momentos"
lang: es
format:
  html:
    toc: false
    theme: cosmo
    code-fold: true
    fig-width: 6
    fig-height: 4
    fontsize: 1.1rem
    grid:
      sidebar-width: 250px
      body-width: 950px
      margin-width: 250px
      gutter-width: 1.5rem
---

```{=html}
<style>
main.content {
text-align: justify}
</style>
```

```{r}
#| include: false

library(tidyverse)
library(knitr)
library(kableExtra)
library(readxl)
library(RColorBrewer)
```



Suponiendo dada una muestra aleatoria de tamaño $n$ para cada una de las siguientes distribuciones realiza lo siguiente:

a) Encuentra el estimador para $\theta$ por el método de momentos.

b) Verifica si es insesgado y/o asintóticamente insesgado.
   
   En este inciso será de utilidad recordar la esperanza de la media muestral:
   
$$E(\overline{X}) = E\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n}\sum_{i=1}^n E(X_i) = \frac{1}{n} n E(X) = E(X).$$


c) Calcula la varianza del estimador.

   Es conveniente recordar algunas propiedades de la varianza que se enuncian en la siguiente proposición:

::: {#prp-varianza}

Sean $X$ y $Y$ dos variables aleatorias con varianza finita y sea $c$ una constante, entonces:

1. $Var(c)=0$.
2. $Var(cX) = c^2 Var(X)$.
3. $Var(X+c) = Var(X)$.
4. $Var(X) = E(X^2) - [E(X)]^2$.
5. $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$, donde 
$$Cov(X,Y) = E[(X - E(X))(Y - E(Y))]$$ 
es la covarianza entre $X$ y $Y$. Si $X$ y $Y$ son independientes, entonces $Cov(X,Y) = 0$ y por lo tanto $Var(X+Y) = Var(X) + Var(Y)$.

:::


Además, dado que en una muestra aleatoria consideramos variables aleatorias independientes:

$$Var{\overline{X}} = Var\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n^2}Var\left(\sum_{i=1}^n X_i\right) = \frac{1}{n^2}\sum_{i=1}^n Var(X_i) = \frac{1}{n^2} n Var(X) = \frac{Var(X)}{n}.$$

d) Calcula el error cuadrático medio (ECM).

e) Elige un valor para $\theta$ y simula una muestra aleatoria de tamaño $n=1000$. Calcula el estimador y para los ejercicios 1 al 4 (distribuciones discretas): genera una muestra aleatoria de tamaño $n=1000$ utilizando el valor estimado del parámetro y compara ambos histogramas. Para los ejercicios 5 al 8 (distribuciones continuas): compara el histograma de los valores simulados con el valor real del parámetro y la función de densidad obtenida con el valor estimado del parámetro.

f) Verifica la convergencia del estimador al aumentar el tamaño cada muestra. Grafica los valores del estimador en función del tamaño de la muestra (puede ser por medio de un boxplot).










::: {#exr-discreta_1}


Para $0 < \theta < 4$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta/4 & \text{si } x = 1, \\
1 - \theta/4 & \text{si } x = 2, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}


::: {.panel-tabset}

### a)Estimador
```{r}
# a) Estimador
set.seed(123)
theta_true <- 2.5   # valor verdadero (0 < theta < 4)
n <- 30             # tamaño de muestra de ejemplo

# generar muestra
X <- sample(c(1,2), size = n, replace = TRUE, prob = c(theta_true/4, 1 - theta_true/4))
n1 <- sum(X == 1)

# estimador
theta_hat <- 4 * (n1 / n)

cat("a) Estimador (ejemplo):\n")
cat("n =", n, " n1 =", n1, " => theta_hat =", theta_hat, "\n")
```


### b)Insesgamiento
```{r}
# b) Insesgamiento (verificación por simulación)
set.seed(1234)
reps <- 10000
n <- 50

n1_sim <- rbinom(reps, size = n, prob = theta_true/4)
theta_hat_sim <- 4 * (n1_sim / n)

sesgo_empirico <- mean(theta_hat_sim) - theta_true

cat("b) Insesgamiento (sim):\n")
cat("Sesgo empírico =", round(sesgo_empirico, 6), "(debería ser cercano a 0)\n")
```


### c)Varianza
```{r}
# c) Varianza (teórica y empírica por simulación)
theta_true <- 2.5
n <- 50
reps <- 10000

# var teórica
var_teo <- (4*theta_true - theta_true^2) / n

# var empírica por simulación
n1_sim <- rbinom(reps, size = n, prob = theta_true/4)
theta_hat_sim <- 4 * (n1_sim / n)
var_empirica <- var(theta_hat_sim)

cat("c) Varianza:\n")
cat("Var teorica =", round(var_teo, 6), "\n")
cat("Var empirica =", round(var_empirica, 6), "\n")
```

### d)ECM
```{r}
# d) ECM (empírico y teórico)
# reutilizamos theta_true, n, reps de arriba

mse_empirica <- mean((theta_hat_sim - theta_true)^2)
mse_teorica <- var_teo  # por insesgamiento

cat("d) ECM:\n")
cat("MSE empirica =", round(mse_empirica, 6), "\n")
cat("MSE teorica  =", round(mse_teorica, 6), "\n")
```

### e)Simulación
```{r}
# e) Simulación Monte Carlo completa
set.seed(2025)
theta_true <- 2.5
reps <- 10000
n_values <- c(30, 100, 1000)

resultados <- data.frame()

for (n in n_values) {
  n1 <- rbinom(reps, size = n, prob = theta_true/4)
  theta_hat <- 4 * (n1 / n)
  
  media_emp <- mean(theta_hat)
  var_emp  <- var(theta_hat)
  mse_emp  <- mean((theta_hat - theta_true)^2)
  sesgo_emp <- media_emp - theta_true
  var_teo  <- (4*theta_true - theta_true^2)/n
  
  resultados <- rbind(resultados, data.frame(
    n=n,
    theta_true=theta_true,
    media_emp=media_emp,
    media_teo=theta_true,
    var_emp=var_emp,
    var_teo=var_teo,
    mse_emp=mse_emp,
    mse_teo=var_teo,
    sesgo_emp=sesgo_emp
  ))
}

print("Resultados de la simulación:")
print(resultados)

# Histograma de la distribución de theta_hat para n = 1000
library(ggplot2)
n_hist <- 1000
n1_hist <- rbinom(reps, size = n_hist, prob = theta_true/4)
theta_hat_hist <- 4 * (n1_hist / n_hist)
df_hist <- data.frame(theta_hat = theta_hat_hist)

ggplot(df_hist, aes(x = theta_hat)) +
  geom_histogram(binwidth = 0.02, color = "black", fill = "lightblue") +
  geom_vline(xintercept = theta_true, color = "red", linetype = "dashed", size = 1) +
  labs(title = paste("Distribución de", expression(hat(theta)), "para n =", n_hist),
       x = expression(hat(theta)), y = "Frecuencia") +
  theme_minimal()
```

### f)Convergencia
```{r}
# f) Convergencia empírica
set.seed(999)
theta_true <- 2.5
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

df_convergencia <- data.frame()

for (n in tamano) {
  estimaciones <- replicate(N, {
    X <- sample(c(1,2), size = n, replace = TRUE, prob = c(theta_true/4, 1 - theta_true/4))
    n1 <- sum(X == 1)
    4 * (n1 / n)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimaciones)
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Boxplot de convergencia
ggplot(df_convergencia, aes(x = n, y = Estimacion, fill = n)) +
  geom_boxplot(alpha = 0.7) +
  geom_hline(yintercept = theta_true, color = "red", linetype = "dashed", size = 1) +
  labs(title = expression(paste("Convergencia de ", hat(theta), " al aumentar n")),
       x = "Tamaño de la muestra (n)",
       y = expression(hat(theta))) +
  theme_minimal() +
  theme(legend.position = "none")
```


:::




:::















::: {#exr-discreta_2}

Para $0 < \theta < 6/5$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta/2 & \text{si } x = -1, \\
\theta/3 & \text{si } x = 0, \\
1-5\theta/6 & \text{si } x = 1, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}


::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{equation}
E(X) = \sum_x x f(x;\theta) = (-1)(\theta
/2) + (0)(\theta/3) + (1)(1-5\theta/6) = 1 - \frac{4\theta}{3}
\end{equation}

Luego, igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{X} = 1 - \frac{4\hat\theta}{3} \implies \hat\theta = \frac{3(1 - \bar{X})}{4}
\end{equation}

## b) Insesgamiento 

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E\left(\frac{3(1 - \overline{X})}{4}\right) = \frac{3}{4}(1 - E(\overline{X})) = \frac{3}{4}(1 - E(X)) = \frac{3}{4}\left(1 - \left(1 - \frac{4\theta}{3}\right)\right) = \theta
\end{equation}

Luego, el estimador es insesgado y por lo tanto, asintóticamente insesgado.


## c) Varianza 

Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = Var\left(\frac{3(1 - \overline{X})}{4}\right) = \left(\frac{3}{4}\right)^2 Var(1 - \overline{X}) = \left(\frac{3}{4}\right)^2 Var(\overline{X}) = \left(\frac{3}{4}\right)^2 \frac{Var(X)}{n}
\end{equation}

Para calcular $Var(X)$ utilizamos la igualdad $Var(X) = E(X^2) - [E(X)]^2$ y para ello, inicialmente calculamos $E(X^2)$:

\begin{equation}
E(X^2) = \sum_x x^2 f(x;\theta) = (-1)^2(\theta/2) + (0)^2(\theta/3) + (1)^2(1 - 5\theta/6) = \frac{\theta}{2} + 1 - \frac{5\theta}{6} = 1 - \frac{\theta}{3}
\end{equation}

Luego, calculamos la varianza de $X$:

\begin{equation}
Var(X) = E(X^2) - [E(X)]^2 = \left(1 - \frac{\theta}{3}\right) - \left(1 - \frac{4\theta}{3}\right)^2 = \frac{-\theta^2 + 6\theta}{9}
\end{equation}  

Finalmente, sustituimos $Var(X)$ en la expresión de $Var(\hat\theta)$:

\begin{equation}
Var(\hat\theta) = \left(\frac{3}{4}\right)^2 \frac{1}{n} \frac{-\theta^2 + 6\theta}{9} = \frac{-\theta^2 + 6\theta}{16n}
\end{equation}

## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{-\theta^2 + 6\theta}{16n}
\end{equation}

## e) Simulación

Elegimos el valor $\theta=1$ y simulamos una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de probabilidad obtenida con el parámetro estimado. 


```{r}
# Parámetro fijo
theta_fijo <- 1

# Función de probabilidad 
dexr <- function(x, theta){
f_x <-ifelse(x == -1, theta/2, ifelse(x == 0, theta/3, ifelse(x == 1, 1 - 5*theta/6, 0)))
return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  X <- sample(c(-1, 0, 1), size = n, replace = TRUE, prob = c(theta/2, theta/3, 1 - 5*theta/6))
  return(X)
}

# Función para estimar theta
estimar_theta <- function(X){
  theta_hat <- (3 * (1 - mean(X))) / 4
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(1000, theta_fijo), Tipo = "Teórico")

theta_hat <- estimar_theta(df_exr$X)

df_temp <- data.frame(X = rexr(1000, theta_hat), Tipo = "Estimados")

df_exr <- rbind(df_exr, df_temp)

ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density), fill =Tipo), bins = 3, center = -1, color = "black", alpha = 0.7, position ="dodge")+
  scale_fill_brewer(palette = "Set1")+
  theme_bw()
  





```


## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra para $n = 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N = 500$ valores.


```{r}
# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados

df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = as.factor(n), Estimacion = estimacion_n)
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```

:::


:::



::: {#exr-discreta_3}

Para $0 < \theta < 3/2$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta/3 & \text{si } x = 0, \\
1-2\theta/3 & \text{si } x = 1, \\
\theta/3 & \text{si } x = 2, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}

### a)Estimador
```{r}
# a) Estimador
set.seed(123)
theta_true <- 1.0   # ejemplo (0 < theta < 1.5)
n <- 50

# generar muestra
X <- sample(c(0,1,2), size = n, replace = TRUE,
            prob = c(theta_true/3, 1 - 2*theta_true/3, theta_true/3))
n0 <- sum(X == 0)
n2 <- sum(X == 2)

# estimador por conteos
theta_hat <- (3/2) * ((n0 + n2) / n)

cat("a) Estimador (ejemplo):\n")
cat("n =", n, " n0 =", n0, " n2 =", n2, " => theta_hat =", theta_hat, "\n")
```

### b)Insesgamiento
```{r}
# b) Insesgamiento (verificación por simulación)
set.seed(2025)
reps <- 10000
n <- 100

# simulamos conteos (binomial con p = 2*theta_true/3)
p_q <- 2 * theta_true / 3
n0n2 <- rbinom(reps, size = n, prob = p_q)   # n0 + n2
theta_hat_sim <- (3/2) * (n0n2 / n)

sesgo_empirico <- mean(theta_hat_sim) - theta_true
cat("b) Sesgo empírico =", round(sesgo_empirico, 6), "(debe ser ~ 0)\n")
```

### c) Varianza
```{r}
# c) Varianza (teórica y empírica por simulación)
theta_true <- 1.0
n <- 100
reps <- 10000

# var teorica
q <- 2 * theta_true / 3
var_teo <- (9 / (4 * n)) * q * (1 - q)  # forma directa
# simplificada:
var_teo_simpl <- (3 * theta_true / (2 * n)) * (1 - 2 * theta_true / 3)

# var empirica por simulación
n0n2_sim <- rbinom(reps, size = n, prob = q)
theta_hat_sim <- (3/2) * (n0n2_sim / n)
var_empirica <- var(theta_hat_sim)

cat("c) Varianza:\n")
cat("Var teorica =", round(var_teo, 8), "\n")
cat("Var teorica (simplificada) =", round(var_teo_simpl, 8), "\n")
cat("Var empirica =", round(var_empirica, 8), "\n")
```

### d)ECM
```{r}
# d) ECM (empírico y teórico)
mse_empirica <- mean((theta_hat_sim - theta_true)^2)
mse_teorica <- var_teo

cat("d) ECM:\n")
cat("MSE empirica =", round(mse_empirica, 8), "\n")
cat("MSE teorica  =", round(mse_teorica, 8), "\n")
```

### e)Simulación
```{r}
# e) Simulación Monte Carlo completa
library(ggplot2)
set.seed(777)
theta_true <- 1.0
reps <- 10000
n_values <- c(30, 100, 1000)

res <- data.frame()

for (n in n_values) {
  # simular n0+n2 como binomial
  q <- 2 * theta_true / 3
  n0n2 <- rbinom(reps, size = n, prob = q)
  theta_hats <- (3/2) * (n0n2 / n)
  
  res <- rbind(res, data.frame(
    n = n,
    media_emp = mean(theta_hats),
    var_emp  = var(theta_hats),
    mse_emp  = mean((theta_hats - theta_true)^2),
    sesgo_emp = mean(theta_hats) - theta_true,
    var_teo  = (9/(4*n))*q*(1-q)
  ))
}

print("Resultados de la simulación:")
print(res)

# Histograma de theta_hat para n = 1000
n_hist <- 1000
q <- 2 * theta_true / 3
n0n2_hist <- rbinom(reps, size = n_hist, prob = q)
theta_hat_hist <- (3/2) * (n0n2_hist / n_hist)
df_hist <- data.frame(theta_hat = theta_hat_hist)

ggplot(df_hist, aes(x = theta_hat)) +
  geom_histogram(binwidth = 0.002, color = "black", fill = "lightblue") +
  geom_vline(xintercept = theta_true, color = "red", linetype = "dashed", size = 1) +
  labs(title = paste("Distribución de", expression(hat(theta)), "para n =", n_hist),
       x = expression(hat(theta)), y = "Frecuencia") +
  theme_minimal()

```

### f) Convergencia
```{r}
# f) Convergencia empírica: boxplots por tamaño de muestra
set.seed(9999)
theta_true <- 1.0
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

df_conv <- data.frame()

for (n in tamano) {
  q <- 2 * theta_true / 3
  n0n2_rep <- rbinom(N, size = n, prob = q)
  ests <- (3/2) * (n0n2_rep / n)
  df_conv <- rbind(df_conv, data.frame(n = factor(n), Estimacion = ests))
}

ggplot(df_conv, aes(x = n, y = Estimacion, fill = n)) +
  geom_boxplot(alpha = 0.7) +
  geom_hline(yintercept = theta_true, color = "red", linetype = "dashed", size = 1) +
  labs(title = expression(paste("Convergencia de ", hat(theta), " al aumentar n")),
       x = "Tamaño de la muestra (n)",
       y = expression(hat(theta))) +
  theme_minimal() +
  theme(legend.position = "none")
```






:::

:::



::: {#exr-discreta_4}

Para $\theta \in \mathbb{N}$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\frac{2x}{\theta(\theta+1)} & \text{si } x = 1, 2, \ldots, \theta, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}

## a) Estimador

Calculamos el estimador para $\theta$.

Inicialmente calculamos la esperanza:

\begin{eqnarray}
E(X) & = & \sum_{x=1}^{\theta} x f(x;\theta)\\
     & = & \frac{2}{\theta(\theta +1)} \sum_{x=1}^\theta x^2\\
     & = & \frac{2\theta +1}{3}
\end{eqnarray}

Igualando $E(X)$ con la media muestral tenemos:

\begin{equation}
E(X) = \overline{X} \implies \frac{2\theta +1}{3} = \overline{X} \implies \hat{\theta} = \frac{3\bar{X}-1}{2} 
\end{equation}

## b) Insesgamiento
```{r}
# b) Insesgamiento - simulación para comparar MM y MLE
set.seed(2025)
theta_true <- 10
reps <- 10000
n <- 50

vals <- 1:theta_true
probs_true <- 2*vals / (theta_true*(theta_true+1))

est_mm <- numeric(reps)
est_mle <- numeric(reps)

for (i in 1:reps) {
  X <- sample(vals, size = n, replace = TRUE, prob = probs_true)
  est_mm[i]  <- (3*mean(X) - 1) / 2
  est_mle[i] <- max(X)
}

sesgo_mm  <- mean(est_mm)  - theta_true
sesgo_mle <- mean(est_mle) - theta_true

cat("b) Sesgo empírico (MM)  =", round(sesgo_mm, 6), "\n")
cat("   Sesgo empírico (MLE) =", round(sesgo_mle, 6), "\n")
```

## c) Varianza
```{r}
# c) Varianza (teórica para MM y empírica por simulación; var MLE empírica)
set.seed(333)
theta_true <- 10
n <- 50
reps <- 10000

# Var teórica para MM
varX <- (theta_true^2 + theta_true - 2) / 18
var_theta_mm_teo <- (theta_true^2 + theta_true - 2) / (8 * n)

# Simulación (reutiliza est_mm y est_mle de antes or recompute)
est_mm <- numeric(reps)
est_mle <- numeric(reps)
vals <- 1:theta_true
probs_true <- 2*vals / (theta_true*(theta_true+1))

for (i in 1:reps) {
  X <- sample(vals, size = n, replace = TRUE, prob = probs_true)
  est_mm[i]  <- (3*mean(X) - 1) / 2
  est_mle[i] <- max(X)
}

var_mm_emp  <- var(est_mm)
var_mle_emp <- var(est_mle)

cat("c) Var teorica (MM) =", round(var_theta_mm_teo, 8), "\n")
cat("   Var empirica (MM) =", round(var_mm_emp, 8), "\n")
cat("   Var empirica (MLE) =", round(var_mle_emp, 8), "\n")

```

## d) ECM
```{r}
# d) ECM (empírico y teórico)
mse_mm_emp  <- mean((est_mm - theta_true)^2)
mse_mle_emp <- mean((est_mle - theta_true)^2)
mse_mm_teo  <- var_theta_mm_teo  # por insesgamiento

cat("d) MSE empirico (MM)  =", round(mse_mm_emp, 8), "\n")
cat("   MSE teorico (MM)   =", round(mse_mm_teo, 8), "\n")
cat("   MSE empirico (MLE) =", round(mse_mle_emp, 8), "\n")

```


## e) Simulación

Elegimos el valor $\theta=5$ y simulamos una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con una muestra obtenida con el valor del estimador. 


```{r}
# Parámetro fijo
theta_fijo <- 10

# Función de probabilidad 
dexr <- function(x, theta){
f_x <- 2*x/(theta * (theta+1))
return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  X <- sample(1:theta, size = n, replace = TRUE, prob = dexr(1:theta, theta))
  return(X)
}

# Función para estimar theta
estimar_theta <- function(X){
  theta_hat <- (3*mean(X)-1)/2
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(1000, theta_fijo), Tipo = "Teórico")

theta_hat <- estimar_theta(df_exr$X)

cat("El valor estimado del parámetro es:", round(theta_hat,4))

df_temp <- data.frame(X = rexr(1000, theta_hat), Tipo = "Estimados")

df_exr <- rbind(df_exr, df_temp)

ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density), fill =Tipo), binwidth = 1, center = 1, color = "black", alpha = 0.7, position ="dodge")+
  scale_fill_brewer(palette = "Set1")+
  theme_bw()
  





```


## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra para $n = 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N = 500$ valores.


```{r}
# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100,150, 500, 1000)
N <- 500

# Data frame para almacenar los resultados

df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = as.factor(n), Estimacion = estimacion_n)
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```




:::



:::

Para poder generar las muestras aleatorias de las distribuciones continuas de los siguientes ejercicios, es necesario enunciar el siguiente teorema:

::: {#thm-inversion}

Si $X$ es una variable aleatoria continua con función de distribución acumulada $F_X(x)$, entonces la variable aleatoria $U = F_X(X)$ tiene una distribución uniforme en el intervalo $(0,1)$. Además, si $U \sim unif(0,1)$, entonces la variable aleatoria $X = F_X^{-1}(U)$ tiene la misma distribución que $X$. 

:::

Para poder aplicar el teorema de inversión, es necesario encontrar la función de distribución acumulada y su inversa. Para que esto último sea posible, es necesario que la función de distribución acumulada sea estrictamente creciente.


::: {#exr-continua_1}

Para $\theta >0$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\frac{2x}{\theta^2} & \text{si } 0\leq x \leq \theta \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}


::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{eqnarray}
E(X) & = & \int_{-\infty}^{\infty} x f(x;\theta) dx \\
     & = & \int_0^{\theta} x \frac{2x}{\theta^2} dx \\
     & = & \frac{2}{\theta^2} \int_0^{\theta} x^2 dx \\
     & = & \frac{2}{\theta^2} \left[\frac{x^3}{3}\right]_0^{\theta} \\
     & = & \frac{2\theta}{3}
\end{eqnarray}

Ahora igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{X} = \frac{2\hat\theta}{3} \implies \hat\theta = \frac{3\overline{X}}{2}
\end{equation}

## b) Insesgamiento

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E\left(\frac{3\overline{X}}{2}\right) = \frac{3}{2}E(\overline{X}) = \frac{3}{2}E(X) = \frac{3}{2}\left(\frac{2\theta}{3}\right) = \theta
\end{equation}

Entonces, el estimador es insesgado y por lo tanto, asintóticamente insesgado.

## c) Varianza

Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = Var\left(\frac{3\overline{X}}{2}\right) = \left(\frac{3}{2}\right)^2 Var(\overline{X}) = \left(\frac{3}{2}\right)^2 \frac{Var(X)}{n}
\end{equation}

Para calcular $Var(X)$ utilizamos la igualdad $Var(X) = E(X^2) - [E(X)]^2$ y para ello, inicialmente calculamos $E(X^2)$:

\begin{eqnarray}
E(X^2) & = & \int_{-\infty}^{\infty} x^2 f(x;\theta) dx \\
       & = & \int_0^{\theta} x^2 \frac{2x}{\theta^2} dx \\
       & = & \frac{2}{\theta^2} \int_0^{\theta} x^3 dx \\
       & = & \frac{2}{\theta^2} \left[\frac{x^4}{4}\right]_0^{\theta} \\
       & = & \frac{\theta^2}{2}
\end{eqnarray}

Luego, calculamos la varianza de $X$:

\begin{equation}
Var(X) = E(X^2) - [E(X)]^2 = \frac{\theta^2}{2} - \left(\frac{2\theta}{3}\right)^2 = \frac{\theta^2}{18}
\end{equation}


Finalmente, sustituimos $Var(X)$ en la expresión de $Var(\hat\theta)$:

\begin{equation}
Var(\hat\theta) = \left(\frac{3}{2}\right)^2 \frac{1}{n}\frac{\theta^2}{18} = \frac{\theta^2}{8n}
\end{equation}

## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{\theta^2}{8n}
\end{equation}


## e) Simulación

Se elige un valor de $\theta = 5$ y se simula una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de densidad obtenida con el parámetro estimado.

En este caso hay que calcular la función de distribución (CDF o probabilidad acumulada)

\begin{eqnarray}
F_X(x;\theta) & = & \int_{-\infty}^{x} f(t;\theta) dt \\
              & = & \int_0^{x} \frac{2t}{\theta^2} dt \\
              & = & \frac{2}{\theta^2} \left[\frac{t^2}{2}\right]_0^{x} \\
              & = & \frac{x^2}{\theta^2}, \quad 0 \leq x \leq \theta
\end{eqnarray}

Observamos que $F_X(x;\theta)$ es estrictamente creciente en el intervalo $(0, \theta)$ y por lo tanto, podemos encontrar su inversa, igualando $U=F_X(x,\theta)$ donde $U \sim unif(0,1)$, tenemos

\begin{equation}
U = \frac{x^2}{\theta^2} \implies x = \theta \sqrt{U}
\end{equation}

Luego, la variable aleatoria $X=F_X^{-1}(U)=\theta \sqrt{U}$ tiene la misma distribución que $X$.


```{r}
#| fig-align: center

# Parámetro fijo

theta_fijo <- 5

# Función de densidad
dexr <- function(x, theta){
  f_x <- ifelse(x >= 0 & x <= theta, (2*x)/(theta^2), 0)
  return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  U <- runif(n)
  X <- theta * sqrt(U)
  return(X)
}


# Función para estimar theta

estimar_theta <- function(X){
  theta_hat <- (3 * mean(X)) / 2
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(5000, theta_fijo))
theta_hat <- estimar_theta(df_exr$X)


ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density)), binwidth =0.25, color = "black", fill = "coral3", alpha = 0.7, boundary=0)+
  stat_function(fun = dexr, args = list(theta = theta_hat), color = "blue", linewidth = 1, xlim = c(0, theta_hat))+
  annotate("text", x = 4, y = 0.15, label = paste("θ =", round(theta_hat,3)), color = "blue", size = 5)+
  labs(title = "Histograma de datos y función de densidad estimada",
       x = "Valores",
       y = "Densidad")+
  theme_minimal()





```
## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra con $n= 10, 50, 100, 500, 100$. Para cada $n$ se generan $N=500$ valores



```{r}
#| fig-align: "center"

# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados
df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n )
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia
ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```



:::


:::



::: {#exr-continua_2}

Para $\theta \in \mathbb{R}$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
e^{-(x-\theta)} & \text{si } \theta \leq x < \infty \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}
### a) Estimador
```{r}
# a) Estimadores (MM y MLE) - ejemplo
set.seed(123)
theta_true <- 2.3    # ejemplo
n <- 50

# generar muestra: X = theta + Exp(1)
X <- theta_true + rexp(n, rate = 1)

# estimadores
theta_hat_mm  <- mean(X) - 1
theta_hat_mle <- min(X)

cat("a) Estimadores (ejemplo):\n")
cat("theta_true =", theta_true, "\n")
cat("theta_hat_MM  =", round(theta_hat_mm, 6), "\n")
cat("theta_hat_MLE =", round(theta_hat_mle, 6), "\n")
```



### b) Insesgamiento
```{r}
# b) Insesgamiento - simulación
set.seed(2025)
theta_true <- 2.3
reps <- 10000
n <- 50

est_mm  <- numeric(reps)
est_mle <- numeric(reps)

for (i in 1:reps) {
  X <- theta_true + rexp(n)
  est_mm[i]  <- mean(X) - 1
  est_mle[i] <- min(X)
}

bias_mm  <- mean(est_mm)  - theta_true
bias_mle <- mean(est_mle) - theta_true

cat("b) Sesgo empírico (MM)  =", round(bias_mm, 6), "(≈ 0)\n")
cat("   Sesgo empírico (MLE) =", round(bias_mle, 6), "(≈ 1/n =", round(1/n,6), ")\n")
```


### c) Varianza 
```{r}
# c) Varianza - teórica y empírica
theta_true <- 2.3
n <- 50
reps <- 10000

# teóricas
var_mm_teo  <- 1 / n
var_mle_teo <- 1 / (n^2)

# empíricas (re-uso de est_mm y est_mle de la simulación anterior)
var_mm_emp  <- var(est_mm)
var_mle_emp <- var(est_mle)

cat("c) Varianzas:\n")
cat("Var teorica (MM)  =", round(var_mm_teo, 8), "\n")
cat("Var empirica (MM) =", round(var_mm_emp, 8), "\n\n")
cat("Var teorica (MLE)  =", round(var_mle_teo, 10), "\n")
cat("Var empirica (MLE) =", round(var_mle_emp, 10), "\n")
```

### d) ECM
```{r}
# d) ECM (empírico y teórico)
mse_mm_emp  <- mean((est_mm - theta_true)^2)
mse_mle_emp <- mean((est_mle - theta_true)^2)

mse_mm_teo  <- var_mm_teo
mse_mle_teo <- (1 / n^2) + (1 / n^2)  # 2/n^2

cat("d) MSE:\n")
cat("MM - MSE empírico =", round(mse_mm_emp, 8), " teórico =", round(mse_mm_teo,8), "\n")
cat("MLE - MSE empírico =", round(mse_mle_emp, 8), " teórico =", round(mse_mle_teo,8), "\n")
```


### e) Simulación
```{r}
# e) Simulación Monte Carlo completa y gráficos
library(ggplot2)
set.seed(777)
theta_true <- 2.3
reps <- 10000
n_values <- c(10, 50, 200)

res <- data.frame()
for (n in n_values) {
  est_mm  <- numeric(reps)
  est_mle <- numeric(reps)
  for (i in 1:reps) {
    X <- theta_true + rexp(n)
    est_mm[i]  <- mean(X) - 1
    est_mle[i] <- min(X)
  }
  res <- rbind(res, data.frame(
    n = n,
    mean_mm = mean(est_mm),
    var_mm  = var(est_mm),
    mse_mm  = mean((est_mm - theta_true)^2),
    mean_mle = mean(est_mle),
    var_mle  = var(est_mle),
    mse_mle  = mean((est_mle - theta_true)^2)
  ))
}

print("Resultados simulación:")
print(res)

# Histograma comparativo para n = 200
n_hist <- 200
est_mm <- numeric(reps)
est_mle <- numeric(reps)
for (i in 1:reps) {
  X <- theta_true + rexp(n_hist)
  est_mm[i]  <- mean(X) - 1
  est_mle[i] <- min(X)
}
df_hist <- data.frame(value = c(est_mm, est_mle),
                      tipo  = rep(c("MM","MLE"), each = reps))

ggplot(df_hist, aes(x = value, fill = tipo)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 80) +
  geom_vline(xintercept = theta_true, color = "red", linetype = "dashed") +
  labs(title = paste("Distribución de estimadores (n =", n_hist, ")"),
       x = expression(hat(theta)), y = "Frecuencia") +
  theme_minimal()
```


### f) Covergencia
```{r}
# f) Convergencia empírica: boxplots por n
set.seed(999)
theta_true <- 2.3
tamano <- c(10, 50, 100, 500)
N <- 500

df_conv <- data.frame()

for (n in tamano) {
  est_mm  <- numeric(N)
  est_mle <- numeric(N)
  for (i in 1:N) {
    X <- theta_true + rexp(n)
    est_mm[i]  <- mean(X) - 1
    est_mle[i] <- min(X)
  }
  df_conv <- rbind(df_conv,
                   data.frame(n = factor(rep(n, 2*N)),
                              Estimacion = c(est_mm, est_mle),
                              Tipo = rep(c("MM","MLE"), each = N)))
}

ggplot(df_conv, aes(x = n, y = Estimacion, fill = Tipo)) +
  geom_boxplot(position = position_dodge(width = 0.8), alpha = 0.7) +
  geom_hline(yintercept = theta_true, color = "red", linetype = "dashed") +
  labs(title = expression("Convergencia: " ~ hat(theta)[MM] ~ " vs " ~ hat(theta)[MLE]),
       x = "Tamaño de la muestra (n)", y = expression(hat(theta))) +
  theme_minimal()

```










:::

:::

::: {#exr-continua_3}

Para $\theta >0$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta x^{\theta-1} & \text{si } 0< x < 1 \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}
### a) Estimador
```{r}
# a) Estimadores (MM y MLE) - ejemplo
set.seed(123)
theta_true <- 2.0   # valor verdadero
n <- 50

# generar muestra: X = U^(1/theta) con U ~ Unif(0,1)
U <- runif(n)
X <- U^(1 / theta_true)

# estimador por momentos
theta_hat_mm <- mean(X) / (1 - mean(X))

# estimador MLE
theta_hat_mle <- - n / sum(log(X))

cat("a) Estimadores (ejemplo):\n")
cat("theta_true =", theta_true, "\n")
cat("theta_hat_MM  =", round(theta_hat_mm, 6), "\n")
cat("theta_hat_MLE =", round(theta_hat_mle, 6), "\n")

```

### b)Insesgamiento
```{r}
# b) Sesgo (simulación)
set.seed(2025)
theta_true <- 2.0
reps <- 10000
n <- 50

est_mm  <- numeric(reps)
est_mle <- numeric(reps)

for (i in 1:reps) {
  X <- runif(n)^(1 / theta_true)
  est_mm[i]  <- mean(X) / (1 - mean(X))
  est_mle[i] <- - n / sum(log(X))
}

bias_mm  <- mean(est_mm)  - theta_true
bias_mle <- mean(est_mle) - theta_true

cat("b) Sesgo empírico (MM)  =", round(bias_mm, 6), "(≈ 0 si n grande)\n")
cat("   Sesgo empírico (MLE) =", round(bias_mle, 6),
    "(teórico =", theta_true/(n-1), ")\n")

```

### c) Varianza
```{r}
# c) Varianzas (teóricas aproximadas y empíricas)
theta_true <- 2.0
n <- 50
reps <- 10000

# var(X)
varX <- theta_true / ((theta_true + 2) * (theta_true + 1)^2)

# var MM (delta method)
var_mm_teo <- ((theta_true + 1)^2 *  (theta_true)) / ((theta_true + 2) * n)

# var MLE teórica (exacta para n>2)
var_mle_teo <- (n^2 * theta_true^2) / ((n-1)^2 * (n-2))

# empírico (reusar simulación previa)
var_mm_emp  <- var(est_mm)
var_mle_emp <- var(est_mle)

cat("c) Varianzas:\n")
cat("Var X (teo) =", round(varX, 8), "\n")
cat("Var MM (teo, delta) =", round(var_mm_teo, 8), "\n")
cat("Var MM (emp) =", round(var_mm_emp, 8), "\n\n")
cat("Var MLE (teo) =", round(var_mle_teo, 8), "(requiere n>2)\n")
cat("Var MLE (emp) =", round(var_mle_emp, 8), "\n")

```


### d) ECM
```{r}
# d) ECM (empírico y teórico aproximado)
mse_mm_emp  <- mean((est_mm - theta_true)^2)
mse_mle_emp <- mean((est_mle - theta_true)^2)

mse_mm_teo  <- var_mm_teo   # aproximación
mse_mle_teo <- var_mle_teo + (theta_true/(n-1))^2  # para n>2

cat("d) MSE:\n")
cat("MM - MSE empírico =", round(mse_mm_emp, 8), " teórico(aprox) =", round(mse_mm_teo,8), "\n")
cat("MLE - MSE empírico =", round(mse_mle_emp, 8), " teórico =", round(mse_mle_teo,8), "\n")

```

### e) Simulación
```{r}
# e) Simulación Monte Carlo: comparar MM y MLE en varios n
library(ggplot2)
set.seed(777)
theta_true <- 2.0
reps <- 10000
n_values <- c(20, 50, 200)

res <- data.frame()

for (n in n_values) {
  est_mm  <- numeric(reps)
  est_mle <- numeric(reps)
  for (i in 1:reps) {
    X <- runif(n)^(1 / theta_true)
    est_mm[i]  <- mean(X) / (1 - mean(X))
    est_mle[i] <- - n / sum(log(X))
  }
  res <- rbind(res, data.frame(
    n = n,
    mean_mm = mean(est_mm), var_mm = var(est_mm), mse_mm = mean((est_mm - theta_true)^2),
    mean_mle = mean(est_mle), var_mle = var(est_mle), mse_mle = mean((est_mle - theta_true)^2)
  ))
}

print(res)

# Histograma comparativo para n = 200
n_hist <- 200
est_mm <- numeric(reps)
est_mle <- numeric(reps)
for (i in 1:reps) {
  X <- runif(n_hist)^(1 / theta_true)
  est_mm[i]  <- mean(X) / (1 - mean(X))
  est_mle[i] <- - n_hist / sum(log(X))
}
df_hist <- data.frame(value = c(est_mm, est_mle),
                      tipo  = rep(c("MM","MLE"), each = reps))
ggplot(df_hist, aes(x = value, fill = tipo)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 80) +
  geom_vline(xintercept = theta_true, color = "red", linetype = "dashed") +
  labs(title = paste("Distribución de estimadores (n =", n_hist, ")"),
       x = expression(hat(theta)), y = "Frecuencia") +
  theme_minimal()

```


### f) Covergencia
```{r}
# f) Convergencia empírica: boxplots por n (MM vs MLE)
set.seed(999)
theta_true <- 2.0
tamano <- c(10, 50, 100, 500)
N <- 500

df_conv <- data.frame()
for (n in tamano) {
  est_mm  <- numeric(N)
  est_mle <- numeric(N)
  for (i in 1:N) {
    X <- runif(n)^(1 / theta_true)
    est_mm[i]  <- mean(X) / (1 - mean(X))
    est_mle[i] <- - n / sum(log(X))
  }
  df_conv <- rbind(df_conv,
                   data.frame(n = factor(rep(n, 2*N)),
                              Estimacion = c(est_mm, est_mle),
                              Tipo = rep(c("MM","MLE"), each = N)))
}

ggplot(df_conv, aes(x = n, y = Estimacion, fill = Tipo)) +
  geom_boxplot(position = position_dodge(width = 0.8), alpha = 0.7) +
  geom_hline(yintercept = theta_true, color = "red", linetype = "dashed") +
  labs(title = expression("Convergencia: " ~ hat(theta)[MM] ~ " vs " ~ hat(theta)[MLE]),
       x = "Tamaño de la muestra (n)", y = expression(hat(theta))) +
  theme_minimal()

```

:::

:::

::: {#exr-continua_4}

Para $\theta >0$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\frac{2(\theta-x)}{\theta^2} & \text{si } 0 < x < \theta \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{eqnarray}
E(X) & = & \int_{0}^{\theta} x f(x;\theta) dx \\
     & = & \frac{\theta}{3} 
\end{eqnarray}

Ahora igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{X} = \frac{\hat\theta}{3} \implies \hat\theta = 3\overline{X}
\end{equation}

## b) Insesgamiento

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E(3\overline{X}) = 3 E(\overline{X}) = 3 \frac{\theta}{3} = \theta
\end{equation}

Entonces, el estimador es insesgado y por lo tanto, asintóticamente insesgado.

## c) Varianza

Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = \frac{\theta^2}{2n}
\end{equation}


## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{\theta^2}{2n}
\end{equation}


## e) Simulación

Se elige un valor de $\theta = 5$ y se simula una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de densidad obtenida con el parámetro estimado.

En este caso hay que calcular la función de distribución (CDF o probabilidad acumulada)

\begin{eqnarray}
F_X(x;\theta) & = & \int_{-\infty}^{x} f(t;\theta) dt \\
              & = & \frac{2x}{\theta}- \frac{x^2}{\theta}
\end{eqnarray}

Observamos que $F_X(x;\theta)$ es estrictamente creciente en el intervalo $(0, \theta)$ y por lo tanto, podemos encontrar su inversa, igualando $U=F_X(x,\theta)$ donde $U \sim unif(0,1)$, tenemos

\begin{equation}
U = \frac{2x}{\theta}- \frac{x^2}{\theta} \implies x = \theta - \theta \sqrt{1-U}
\end{equation}

Luego, la variable aleatoria $X=F_X^{-1}(U)=\theta + \theta \sqrt{1+U}$ tiene la misma distribución que $X$.


```{r}
#| fig-align: center

# Parámetro fijo

theta_fijo <- 5

# Función de densidad
dexr <- function(x, theta){
  f_x <- 2*(theta-x)/(theta^2)
  return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  U <- runif(n)
  X <- theta  - theta * sqrt(1-U)
  return(X)
}


# Función para estimar theta

estimar_theta <- function(X){
  theta_hat <- (3 * mean(X)) 
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(5000, theta_fijo))
theta_hat <- estimar_theta(df_exr$X)


ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density)), binwidth =0.25, color = "black", fill = "coral3", alpha = 0.7, boundary=0)+
  stat_function(fun = dexr, args = list(theta = theta_hat), color = "blue", linewidth = 1, xlim = c(0, theta_hat))+
  annotate("text", x = 4, y = 0.15, label = paste("θ =", round(theta_hat,3)), color = "blue", size = 5)+
  labs(title = "Histograma de datos y función de densidad estimada",
       x = "Valores",
       y = "Densidad")+
  theme_minimal()





```
## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra con $n= 10, 50, 100, 500, 100$. Para cada $n$ se generan $N=500$ valores



```{r}
#| fig-align: "center"

# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados
df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n )
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia
ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```



:::


:::


Los siguientes ejercicios requieren el uso de datos contenidos en el archivo `Tarea_4.xlsx`. 

```{r}
datos <- read_xlsx("./Tarea_4.xlsx")
```





::: {#exr-valores_1}

Las observaciones de la columna `Geometrica` provienen de una distribución geométrica con parámetro $\theta$. Calcula la estimación de $\theta$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

```{r}
# Ejercicio 9 versión discreta
# Ejercicio 9 versión discreta
p_hat <- 1 / mean(datos$Geometrica)
p_hat

ggplot(datos, aes(x = Geometrica)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 20, color = "black", fill = "green3", alpha = 0.7, boundary = 0) +
  geom_point(data = data.frame(x = 1:max(datos$Geometrica),
                               y = dgeom(1:max(datos$Geometrica) - 1, prob = p_hat)),
             aes(x = x, y = y),
             color = "red", size = 2) +
  geom_line(data = data.frame(x = 1:max(datos$Geometrica),
                              y = dgeom(1:max(datos$Geometrica) - 1, prob = p_hat)),
            aes(x = x, y = y), color = "green") +
  annotate("text", x = mean(datos$Geometrica), y = 0.15,
           label = paste("p̂ =", round(p_hat, 3)), color = "blue", size = 5) +
  labs(title = "Histograma de datos y función de probabilidad estimada (Geométrica)",
       x = "Valores", y = "Densidad") +
  theme_minimal()




```




```

:::


::: {#exr-valores_2}

Las observaciones de la columna `Exp` provienen de una distribución exponencial con parámetro $\theta$. Calcula la estimación de $\theta$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.


```{r}
#Ejercicio 10 Distribución Exponencial
lambda_hat <- 1/mean(datos$Exp)
lambda_hat

ggplot(datos)+
  geom_histogram(aes(Exp, y = after_stat(density)), bins = 50, color = "darkred", fill = "coral", alpha = 0.7, boundary=0)+
  stat_function(fun = dexp, args = list(rate = lambda_hat), color = "green", linewidth = 1)+
  annotate("text", x = 0.75, y = 2, label = paste("λ =", round(lambda_hat, 3)), color = "green", size = 5)+
  labs(title = "Histograma de datos y función de densidad estimada",
       x = "Valores",
       y = "Densidad")+
  theme_minimal()


```



:::


::: {#exr-valores_3}

Las observaciones de la columna `Normal` provienen de una distribución normal con parámetros $\mu$ y $\sigma^2$. Calcula la estimación de $\mu$ y $\sigma^2$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

```{r}
# Ejercicio 11: Distribución Normal
mu_hat <- mean(datos$Normal)
sigma_hat <- sd(datos$Normal)

mu_hat
sigma_hat

ggplot(datos) +
  geom_histogram(aes(Normal, y = after_stat(density)),
                 bins = 40, color = "darkgreen", fill = "orange", alpha = 0.7, boundary = 0) +
  stat_function(fun = dnorm,
                args = list(mean = mu_hat, sd = sigma_hat),
                color = "red", linewidth = 1) +
  annotate("text", x = mu_hat, y = 0.4,
           label = paste("μ̂ =", round(mu_hat, 3), "\nσ̂ =", round(sigma_hat, 3)),
           color = "blue", size = 5) +
  labs(title = "Histograma de datos y función de densidad estimada (Normal)",
       x = "Valores", y = "Densidad") +
  theme_minimal()

```

:::


::: {#exr-valores_4}

Las observaciones de la columna `Gamma` provienen de una distribución gamma con parámetros $\gamma$ y $\lambda$. Calcula la estimación de $\gamma$ y $\lambda$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

```{r}
# Ejercicio 12: Distribución Gamma
media_gamma <- mean(datos$Gamma)
var_gamma <- var(datos$Gamma)

alpha_hat <- (media_gamma^2) / var_gamma
beta_hat <- media_gamma / var_gamma

alpha_hat
beta_hat

ggplot(datos) +
  geom_histogram(aes(Gamma, y = after_stat(density)),
                 bins = 40, color = "darkblue", fill = "yellow", alpha = 0.7, boundary = 0) +
  stat_function(fun = dgamma,
                args = list(shape = alpha_hat, rate = beta_hat),
                color = "green", linewidth = 1) +
  annotate("text", x = media_gamma, y = 0.5,
           label = paste("α̂ =", round(alpha_hat, 3),
                         "\nβ̂ =", round(beta_hat, 3)),
           color = "green", size = 5) +
  labs(title = "Histograma de datos y función de densidad estimada (Gamma)",
       x = "Valores", y = "Densidad") +
  theme_minimal()

```

:::
